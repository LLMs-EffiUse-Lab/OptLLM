{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11007561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T22:30:41.771603700Z",
     "start_time": "2024-02-07T22:30:40.765483Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51425c38",
   "metadata": {},
   "source": [
    "### Download the word vector from https://fasttext.cc/docs/en/english-vectors.html\n",
    "Pre-trained word vectors:\n",
    "- wiki-news-300d-1M.vec.zip: 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\n",
    "- wiki-news-300d-1M-subword.vec.zip: 1 million word vectors trained with subword infomation on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\n",
    "- crawl-300d-2M.vec.zip: 2 million word vectors trained on Common Crawl (600B tokens).\n",
    "- crawl-300d-2M-subword.zip: 2 million word vectors trained with subword information on Common Crawl (600B tokens) (** current one **)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4a515c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T00:55:53.629687600Z",
     "start_time": "2024-02-05T00:53:03.278788500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the FastText model from the file\n",
    "model = load_facebook_vectors(\n",
    "    \"./word_models/crawl-300d-2M-subword/crawl-300d-2M-subword.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get word vectors ###\n",
    "# model.word_vec('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5db452d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T22:30:47.859916900Z",
     "start_time": "2024-02-07T22:30:47.841409400Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/text_classification/\"\n",
    "model_names = [\"gptneox_20B\", \"gptj_6B\", \"fairseq_gpt_13B\", \"text-davinci-002\", \"text-curie-001\",\n",
    "               \"gpt-3.5-turbo\", \"gpt-4\", \"j1-jumbo\", \"j1-grande\", \"j1-large\", \"xlarge\", \"medium\"]\n",
    "answer_column = \"ref_answer\"\n",
    "query_name = \"content\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews 7600\n",
      "coqa 7982\n",
      "headlines 10000\n",
      "overruling 2160\n",
      "sciq 11677\n"
     ]
    }
   ],
   "source": [
    "# single dataset preprocess\n",
    "datasets = ['agnews', 'coqa', 'headlines', 'overruling', 'sciq']\n",
    "\n",
    "for dataset in datasets:\n",
    "    job_data = pd.read_csv(f\"{data_dir}/{dataset}.csv\")\n",
    "    X = []\n",
    "    Y = []\n",
    "    cost = []\n",
    "    for _, row in job_data.iterrows():\n",
    "        X.append({'dataset': dataset, 'query': row[query_name]})\n",
    "        Y.append({k: row[f\"{k}_answer\"] == row[answer_column] for k in model_names})\n",
    "        cost.append({k: row[f\"{k}_cost\"] for k in model_names})\n",
    "    X_features_word2vec = [{'dataset': x['dataset'], 'features': extract_features_word2vec(x['query'])} for x in X]\n",
    "    Y = [{k: 1 if v else 0 for k, v in y.items()} for y in Y]\n",
    "    print(dataset, len(job_data))\n",
    "    with open(f\"{dataset}_content_word2vec.pkl\", mode=\"wb\") as f:\n",
    "        pickle.dump((X_features_word2vec, Y, cost), f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T04:54:25.719934Z",
     "start_time": "2024-02-05T04:54:01.395562400Z"
    }
   },
   "id": "996bd0c011af708c",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/log_parsing/\"\n",
    "model_names = [\"j2_mid\", \"j2_ultra\", \"Mixtral_8x7B\", \"llama2_7b\", \"llama2_13b\",\n",
    "               \"llama2_70b\", \"Yi_34B\", \"Yi_6B\"]\n",
    "answer_column = \"ref_answer\"\n",
    "query_name = \"content\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T04:57:14.374946300Z",
     "start_time": "2024-02-05T04:57:14.353846700Z"
    }
   },
   "id": "a14cd7a38664c3af",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n"
     ]
    }
   ],
   "source": [
    "logs_df = pd.read_csv(f\"{data_dir}/log_parsing.csv\")\n",
    "X = []\n",
    "Y = []\n",
    "cost = []\n",
    "for _, row in logs_df.iterrows():\n",
    "    X.append({'dataset': row[\"dataset\"], 'query': row[query_name]})\n",
    "    Y.append({k: row[f\"{k}_answer\"] == row[answer_column] for k in model_names})\n",
    "    cost.append({k: row[f\"{k}_cost\"] for k in model_names})\n",
    "X_features_word2vec = [{'dataset': x['dataset'], 'features': extract_features_word2vec(x['query'])} for x in X]\n",
    "Y = [{k: 1 if v else 0 for k, v in y.items()} for y in Y]\n",
    "print(len(logs_df))\n",
    "with open(f\"logs_df_{query_name}_word2vec.pkl\", mode=\"wb\") as f:\n",
    "    pickle.dump((X_features_word2vec, Y, cost), f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T04:59:21.420342500Z",
     "start_time": "2024-02-05T04:59:07.206347500Z"
    }
   },
   "id": "42448b6d7a882260",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c054b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV files\n",
    "def get_query_only(text):\n",
    "    query = text.split(\"\\n\")[-2]\n",
    "    query = query[query.find(\":\") + 1:].strip()\n",
    "    return query\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "cost = []\n",
    "for fname in os.listdir(data_dir):\n",
    "    fpath = os.path.join(data_dir, fname)\n",
    "    news_df = pd.read_csv(fpath)\n",
    "    for _, row in news_df.iterrows():\n",
    "        X.append({'dataset': fname[:-4], 'query': row[query_name]})\n",
    "        Y.append({k: row[f\"{k}_answer\"] == row[answer_column] for k in model_names})\n",
    "        cost.append({k: row[f\"{k}_cost\"] for k in model_names})"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edea45374affe40f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [{k: 1 if v else 0 for k, v in y.items()} for y in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99bde5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T06:08:36.637256700Z",
     "start_time": "2024-02-04T06:08:36.623641300Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_word2vec(text):\n",
    "    words = text.strip().split()\n",
    "    word_vecs = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vecs.append(model.get_vector(word.strip()))\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "    return np.mean(word_vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_word2vec = [{'dataset': x['dataset'], 'features': extract_features_word2vec(x['query'])} for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b3be29f031beb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4400f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a file\n",
    "import pickle\n",
    "with open(\"content_word2vec.pkl\", mode=\"wb\") as f:\n",
    "    pickle.dump((X_features_word2vec, Y, cost), f)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"content\"  # content\n",
    "with open(f\"{file_name}_word2vec.pkl\", mode=\"rb\") as f:\n",
    "    X, Y, cost = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T00:07:48.025843400Z",
     "start_time": "2024-02-07T00:07:47.738666100Z"
    }
   },
   "id": "75addbe92b46bae8",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"content\"  # content\n",
    "with open(f\"logs_df_{file_name}_word2vec.pkl\", mode=\"rb\") as f:\n",
    "    X, Y, cost = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T05:40:43.422252400Z",
     "start_time": "2024-02-05T05:40:43.280767700Z"
    }
   },
   "id": "45d541541e78d768",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datasets = ['agnews', 'coqa', 'headlines', 'overruling', 'sciq']\n",
    "dataset = \"agnews\"\n",
    "# for dataset in datasets:\n",
    "with open(f\"{dataset}_word2vec.pkl\", mode=\"rb\") as f:\n",
    "    X, Y, cost = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:31:16.500585400Z",
     "start_time": "2024-02-07T22:31:16.454076400Z"
    }
   },
   "id": "3cb243feadce2358",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a829d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T22:31:25.181171700Z",
     "start_time": "2024-02-07T22:31:22.500023500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYue7\\anaconda3\\envs\\llms\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\LYue7\\anaconda3\\envs\\llms\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from helpers import split_train_test_random, split_train_test_dataset, split_train_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b472e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T22:31:27.978545100Z",
     "start_time": "2024-02-07T22:31:27.849431Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for i in range(len(X)):\n",
    "    infor_dict = {}\n",
    "    infor_dict['features'] = X[i]['features']\n",
    "    infor_dict['label'] = Y[i]\n",
    "    infor_dict['cost'] = cost[i]\n",
    "    data_dict[i] = infor_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:31:29.336848600Z",
     "start_time": "2024-02-07T22:31:29.304843800Z"
    }
   },
   "id": "c099170a152d956a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data_dict, test_size=0.99, random_state=42)\n",
    "train_x, train_y, test_x, test_y = split_train_test_(train_data, test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:31:33.543643900Z",
     "start_time": "2024-02-07T22:31:33.514639Z"
    }
   },
   "id": "252a42e89c5020b6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "76"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:37:10.245058500Z",
     "start_time": "2024-02-07T22:37:10.215059300Z"
    }
   },
   "id": "14a6bcc87288d39",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "gptneox_20B         0.513158\ngptj_6B             0.618421\nfairseq_gpt_13B     0.776316\ntext-davinci-002    0.934211\ntext-curie-001      0.723684\ngpt-3.5-turbo       0.868421\ngpt-4               0.894737\nj1-jumbo            0.894737\nj1-grande           0.828947\nj1-large            0.763158\nxlarge              0.868421\nmedium              0.565789\ndtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = pd.DataFrame([x['label'] for x in train_data])\n",
    "score = label.sum(axis=0) / len(label)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:38:55.260751700Z",
     "start_time": "2024-02-07T22:38:55.174736100Z"
    }
   },
   "id": "eb9806f854a6f630",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_x = [x['features'] for x in train_data]\n",
    "train_y = [list(y['label'].values()) for y in train_data]\n",
    "test_x = [x['features'] for x in test_data]\n",
    "test_y = [list(y['label'].values()) for y in test_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T00:08:03.579101100Z",
     "start_time": "2024-02-07T00:08:03.507664400Z"
    }
   },
   "id": "96078d5753887cc9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, train_y, test_x, test_y = split_train_test_random(X, Y, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cost = [x['cost'] for x in test_data]\n",
    "cost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6a8f498655cd6f4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26c4fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:08:35.418390600Z",
     "start_time": "2024-02-07T00:08:14.940155500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              learning_rate=None, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=100, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=1000, n_jobs=-1,\n                                              num_parallel_tree=None,\n                                              random_state=None, ...))",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              learning_rate=None, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=100, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=1000, n_jobs=-1,\n                                              num_parallel_tree=None,\n                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=None,\n                                              learning_rate=None, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=100, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=1000, n_jobs=-1,\n                                              num_parallel_tree=None,\n                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=100, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=-1,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=100, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=-1,\n              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultiOutputClassifier(estimator=XGBClassifier(n_jobs=-1, max_depth=100, n_estimators=1000))\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db60623a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:08:38.056154600Z",
     "start_time": "2024-02-07T00:08:35.332136100Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_x[0:])\n",
    "y_score = clf.predict_proba(test_x[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193cf5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:08:38.073267400Z",
     "start_time": "2024-02-07T00:08:38.057154800Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\"gptneox_20B\", \"gptj_6B\", \"fairseq_gpt_13B\", \"text-davinci-002\", \"text-curie-001\",\n",
    "               \"gpt-3.5-turbo\", \"gpt-4\", \"j1-jumbo\", \"j1-grande\", \"j1-large\", \"xlarge\", \"medium\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34808a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T00:08:38.412310Z",
     "start_time": "2024-02-07T00:08:38.074270200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     gptneox_20B      0.704     0.760     0.731     22808\n",
      "         gptj_6B      0.716     0.740     0.728     22789\n",
      " fairseq_gpt_13B      0.688     0.779     0.731     23065\n",
      "text-davinci-002      0.779     0.872     0.823     27220\n",
      "  text-curie-001      0.679     0.765     0.720     21978\n",
      "   gpt-3.5-turbo      0.765     0.832     0.797     24110\n",
      "           gpt-4      0.797     0.877     0.835     27568\n",
      "        j1-jumbo      0.739     0.847     0.789     25783\n",
      "       j1-grande      0.707     0.854     0.774     24818\n",
      "        j1-large      0.690     0.822     0.750     23498\n",
      "          xlarge      0.767     0.849     0.806     25923\n",
      "          medium      0.691     0.776     0.731     22372\n",
      "\n",
      "       micro avg      0.729     0.818     0.771    291932\n",
      "       macro avg      0.727     0.815     0.768    291932\n",
      "    weighted avg      0.730     0.818     0.771    291932\n",
      "     samples avg      0.623     0.656     0.602    291932\n",
      "\n",
      "0.20597053171044202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYue7\\anaconda3\\envs\\llms\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\LYue7\\anaconda3\\envs\\llms\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(test_y, y_pred, digits=3,\n",
    "                            target_names=model_names\n",
    "                            ))\n",
    "print(accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m y_pred_lr \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(test_x[\u001B[38;5;241m0\u001B[39m:])\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# print(classification_report(test_y, y_pred_lr, digits=3,target_names=model_names))\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred_lr\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 220\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     90\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     95\u001B[0m             type_true, type_pred\n\u001B[0;32m     96\u001B[0m         )\n\u001B[0;32m     97\u001B[0m     )\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    100\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(train_x, train_y)\n",
    "y_pred_lr = model.predict(test_x[0:])\n",
    "# print(classification_report(test_y, y_pred_lr, digits=3,target_names=model_names))\n",
    "print(accuracy_score(test_y, y_pred_lr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T00:11:32.161305400Z",
     "start_time": "2024-02-07T00:11:31.956157400Z"
    }
   },
   "id": "447299da1bf4c187",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a10637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a new query\n",
    "query = \"What is the capital of France?\"\n",
    "query_features = extract_features_word2vec(query)\n",
    "# query_features = X[0]['features'] # to test\n",
    "y_pred = clf.predict([query_features])\n",
    "y_score = clf.predict_proba([query_features])\n",
    "# print(y_pred)\n",
    "# print(y_score)\n",
    "score = {k: v[0][1] for k, v in zip(model_names, y_score)}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2636a628d61266c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "job_data = pd.read_csv(\"../datasets/text_queries.csv\")\n",
    "X_features_word2vec = job_data['query'].apply(extract_features_word2vec)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6127e16f04dfd29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Y = []\n",
    "for _, row in job_data.iterrows():\n",
    "    Y.append({k: row[f\"{k}_answer\"] == row[answer_column] for k in model_names})\n",
    "\n",
    "Y = [{k: 1 if v else 0 for k, v in y.items()} for y in Y]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac4d81fe77d49c18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f08106789246599",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "job_data[\"content\"].head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ad3593d44716776",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logging' from 'huggingface_hub' (C:\\Users\\LYue7\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprediction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprediction_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m datasets \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogs\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;66;03m#'overruling', 'agnews', 'coqa', 'headlines', 'sciq']\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n",
      "File \u001B[1;32mD:\\GitHub\\IGSwithPrediction\\prediction\\prediction_model.py:4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpickle\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfasttext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_facebook_vectors\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprediction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhelpers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m classification_report, accuracy_score\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "File \u001B[1;32mD:\\GitHub\\IGSwithPrediction\\prediction\\helpers.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertModel, BertTokenizer\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfasttext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_facebook_vectors\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\transformers\\__init__.py:26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dependency_versions_check\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     28\u001B[0m     OptionalDependencyNotAvailable,\n\u001B[0;32m     29\u001B[0m     _LazyModule,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     46\u001B[0m     logging,\n\u001B[0;32m     47\u001B[0m )\n\u001B[0;32m     50\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)  \u001B[38;5;66;03m# pylint: disable=invalid-name\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdependency_versions_table\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deps\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m require_version, require_version_core\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# define which module versions we always want to check at run time\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# order specific notes:\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# - tqdm must be checked before tokenizers\u001B[39;00m\n\u001B[0;32m     25\u001B[0m pkgs_to_check_at_runtime \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtqdm\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyyaml\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     38\u001B[0m ]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\transformers\\utils\\__init__.py:18\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#!/usr/bin/env python\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# coding=utf-8\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_full_repo_name  \u001B[38;5;66;03m# for backward compatibility\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m version\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\__init__.py:370\u001B[0m, in \u001B[0;36m_attach.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m attr_to_modules:\n\u001B[0;32m    369\u001B[0m     submod_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_to_modules[name]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 370\u001B[0m     submod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubmod_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    371\u001B[0m     attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(submod, name)\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;66;03m# If the attribute lives in a file (module) with the same\u001B[39;00m\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001B[39;00m\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;66;03m# the module is accessible on the package.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\hf_api.py:51\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm \u001B[38;5;28;01mas\u001B[39;00m base_tqdm\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontrib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconcurrent\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m thread_map\n\u001B[1;32m---> 51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_commit_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     52\u001B[0m     CommitOperation,\n\u001B[0;32m     53\u001B[0m     CommitOperationAdd,\n\u001B[0;32m     54\u001B[0m     CommitOperationCopy,\n\u001B[0;32m     55\u001B[0m     CommitOperationDelete,\n\u001B[0;32m     56\u001B[0m     _fetch_lfs_files_to_copy,\n\u001B[0;32m     57\u001B[0m     _fetch_upload_modes,\n\u001B[0;32m     58\u001B[0m     _prepare_commit_payload,\n\u001B[0;32m     59\u001B[0m     _upload_lfs_files,\n\u001B[0;32m     60\u001B[0m     _warn_on_overwriting_operations,\n\u001B[0;32m     61\u001B[0m )\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inference_endpoints\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m InferenceEndpoint, InferenceEndpointType\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_multi_commits\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     64\u001B[0m     MULTI_COMMIT_PR_CLOSE_COMMENT_FAILURE_BAD_REQUEST_TEMPLATE,\n\u001B[0;32m     65\u001B[0m     MULTI_COMMIT_PR_CLOSE_COMMENT_FAILURE_NO_CHANGES_TEMPLATE,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     74\u001B[0m     plan_multi_commits,\n\u001B[0;32m     75\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\_commit_api.py:17\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING, Any, BinaryIO, Dict, Iterable, Iterator, List, Literal, Optional, Tuple, Union\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontrib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconcurrent\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m thread_map\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_session\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ENDPOINT, HF_HUB_ENABLE_HF_TRANSFER\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlfs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UploadInfo, lfs_upload, post_lfs_batch_info\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\__init__.py:370\u001B[0m, in \u001B[0;36m_attach.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m attr_to_modules:\n\u001B[0;32m    369\u001B[0m     submod_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_to_modules[name]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 370\u001B[0m     submod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubmod_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    371\u001B[0m     attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(submod, name)\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;66;03m# If the attribute lives in a file (module) with the same\u001B[39;00m\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001B[39;00m\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;66;03m# the module is accessible on the package.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\utils\\__init__.py:108\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_validators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     96\u001B[0m     HFValidationError,\n\u001B[0;32m     97\u001B[0m     smoothly_deprecate_use_auth_token,\n\u001B[0;32m     98\u001B[0m     validate_hf_hub_args,\n\u001B[0;32m     99\u001B[0m     validate_repo_id,\n\u001B[0;32m    100\u001B[0m )\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m    102\u001B[0m     are_progress_bars_disabled,\n\u001B[0;32m    103\u001B[0m     disable_progress_bars,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    106\u001B[0m     tqdm_stream_file,\n\u001B[0;32m    107\u001B[0m )\n\u001B[1;32m--> 108\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_telemetry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m send_telemetry\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\utils\\_telemetry.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict, Optional, Union\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01murllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m quote\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constants, logging\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_hf_headers, get_session, hf_raise_for_status\n\u001B[0;32m     10\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'logging' from 'huggingface_hub' (C:\\Users\\LYue7\\anaconda3\\envs\\llms\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from prediction.prediction_model import *\n",
    "datasets = ['logs'] #'overruling', 'agnews', 'coqa', 'headlines', 'sciq']\n",
    "for dataset in datasets:\n",
    "    test_data_size = 0.99\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "    data_dir = f\"../datasets/text_classification\"\n",
    "    save_dir = f\"output/text_classification/query_{test_data_size}/{dataset}_{test_data_size}\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # if dataset == \"text_classification\":\n",
    "    # model_list = ['gptneox_20B', 'gptj_6B', 'fairseq_gpt_13B', 'text-davinci-002', 'text-curie-001', 'gpt-3.5-turbo',\n",
    "    #                   'gpt-4', 'j1-jumbo', 'j1-grande', 'j1-large', 'xlarge', 'medium']\n",
    "    # elif dataset == \"log_parsing\":\n",
    "    model_names = [\"j2_mid\", \"j2_ultra\", \"Mixtral_8x7B\", \"llama2_7b\", \"llama2_13b\", \"llama2_70b\", \"Yi_34B\", \"Yi_6B\"]\n",
    "\n",
    "    df_pre_accuracy, df_true_accuracy, df_cost = data_preprocess(data_dir, dataset, model_names, test_size=test_data_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T05:29:08.347370800Z",
     "start_time": "2024-02-05T05:29:06.964269500Z"
    }
   },
   "id": "9c1a589359bbee64",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2b4189a941d26f93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
